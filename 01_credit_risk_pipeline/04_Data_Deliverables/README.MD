# Data Deliverables & Artifacts

This folder contains the quantitative outputs and model artifacts generated by the Credit Risk Pipeline. These files are designed for integration into downstream business intelligence (BI) tools or for use in model deployment.

## ðŸ“Š Key Deliverables

### 1. Threshold Performance Analysis (`threshold_analysis.csv`)
* **Description**: A comprehensive sweep of classification thresholds from 0.1 to 0.6.
* **Contents**: Performance metrics (Precision, Recall, F1-Score) alongside business metrics like "Approved %" and "Default Rate Among Approved %".
* **Usage**: Used to justify the selection of the 0.45 recommended threshold.

### 2. Final Model Metrics Summary (`model_performance_summary.json`)
* **Description**: A high-level snapshot of the final model's performance on the hold-out test set.
* **Key Stats**: AUC-ROC (0.7042), Average Precision (0.369), and the Confusion Matrix data.

### 3. Feature Importance Data (`feature_importance.csv`)
* **Description**: The numerical importance scores for the 40 engineered features.
* **Usage**: Supporting data for SHAP global importance visualizations to track the influence of Grade, DTI, and FICO.

---

## ðŸ’¾ Deployment Ready Artifacts (Optional)
* **`approval_model.json`**: The serialized XGBoost model for the Stage 1 Approval Filter.
* **`default_risk_model.json`**: The serialized XGBoost model for the Stage 2 Risk Engine.
* **`requirements.txt`**: A full list of Python library versions required to ensure environment parity in production.
